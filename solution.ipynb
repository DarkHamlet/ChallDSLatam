{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28bd23ab",
   "metadata": {},
   "source": [
    "# Data Scientist Challenge - LATAM Airlines\n",
    "\n",
    "## Instrucciones\n",
    "\n",
    "En Advanced Analytics valoramos muchísimo el trabajo en equipo y la constante interacción entre los distintos roles que trabajan en un producto basado en datos, como el Data Scientist, Machine Learning Engineering, Data Engineer, entre otros. Es por este motivo que una habilidad esencial que buscamos a la hora de buscar nuevos integrantes es el manejo adecuado de git. Este desafío deberá ser entregado en la plataforma de git que más te acomode y que sea pública para que la podamos revisar. Lo que buscamos con esto es poder entender de mejor manera el desarrollo que generaste con tu código, cómo lo fuiste mejorando en el tiempo y si tienes proyectos propios en este repositorio nos servirán para conocer mejor tu experiencia en base a tu propio\n",
    "portafolio.\n",
    "\n",
    "Instrucciones Git:\n",
    "1) Crear un repositorio en la plataforma de git que más te acomode y que sea pública\n",
    "2) Haber trabajado con una rama principal y otra de desarrollo. Opcional, ocupar alguna práctica de desarrollo de GitFlow.\n",
    "Instrucciones del desafío:\n",
    "1) Debes enviar el link al repositorio al mail del que fuiste contactado con asunto Challenge Data Scientist - [Nombre][Apellido], ejemplo Challenge Data Scientist - Pedro Pica Piedra.\n",
    "2) Se aceptará los cambios en el repositorio hasta la fecha y hora que se indique en el mail.\n",
    "3) En la siguiente carpeta de Google Drive encontrarás las instrucciones del desafío y el archivo `dataset_SCL.csv` que utilizarás para desarrollarlo.\n",
    "4) El repositorio debe tener un jupyter notebook llamado solution.ipynb utilizando python 3. No serán revisados otros\n",
    "lenguajes como R o similar.\n",
    "5) En solution.ipynb deben estar resueltas las respuestas a todas las preguntas del desafío\n",
    "6) Dentro del repositorio deben estar todos los archivos necesarios para que los evaluadores puedan clonar y luego correr tu\n",
    "notebook sin problemas\n",
    "7) Una copia de tu CV (curriculum vitae) en formato .pdf en el repositorio\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4003ac",
   "metadata": {},
   "source": [
    "## Problema\n",
    "\n",
    "El problema consiste en predecir la probabilidad de atraso de los vuelos que aterrizan o despegan del aeropuerto de Santiago de\n",
    "Chile (SCL). Para eso les entregamos un dataset usando datos públicos y reales donde cada fila corresponde a un vuelo que\n",
    "aterrizó o despegó de SCL. Para cada vuelo se cuenta con la siguiente información:\n",
    "\n",
    "Fecha-I : Fecha y hora programada del vuelo.\n",
    "\n",
    "Vlo-I : Número de vuelo programado.\n",
    "\n",
    "Ori-I : Código de ciudad de origen programado.\n",
    "\n",
    "Des-I : Código de ciudad de destino programado.\n",
    "\n",
    "Emp-I : Código aerolínea de vuelo programado.\n",
    "\n",
    "Fecha-O : Fecha y hora de operación del vuelo.\n",
    "\n",
    "Vlo-O : Número de vuelo de operación del vuelo.\n",
    "\n",
    "Ori-O : Código de ciudad de origen de operación\n",
    "\n",
    "Des-O : Código de ciudad de destino de operación.\n",
    "\n",
    "Emp-O : Código aerolínea de vuelo operado.\n",
    "\n",
    "DIA : Día del mes de operación del vuelo.\n",
    "\n",
    "MES : Número de mes de operación del vuelo.\n",
    "\n",
    "AÑO : Año de operación del vuelo.\n",
    "\n",
    "DIANOM : Día de la semana de operación del vuelo.\n",
    "\n",
    "TIPOVUELO : Tipo de vuelo, I =Internacional, N =Nacional.\n",
    "\n",
    "OPERA : Nombre de aerolínea que opera.\n",
    "\n",
    "SIGLAORI : Nombre ciudad origen.\n",
    "\n",
    "SIGLADES : Nombre ciudad destino.\n",
    "\n",
    "### Desafío\n",
    "1. ¿Cómo se distribuyen los datos? ¿Qué te llama la atención o cuál es tu conclusión sobre esto?\n",
    "2. Genera las columnas adicionales y luego expórtelas en un archivo synthetic_features.csv :\n",
    "○ temporada_alta : 1 si Fecha-I está entre 15-Dic y 3-Mar, o 15-Jul y 31-Jul, o 11-Sep y 30-Sep, 0 si no.\n",
    "○ dif_min : diferencia en minutos entre Fecha-O y Fecha-I .\n",
    "○ atraso_15 : 1 si dif_min > 15, 0 si no.\n",
    "○ periodo_dia : mañana (entre 5:00 y 11:59), tarde (entre 12:00 y 18:59) y noche (entre 19:00 y 4:59), en base a\n",
    "Fecha-I .\n",
    "3. ¿Cómo se compone la tasa de atraso por destino, aerolínea, mes del año, día de la semana, temporada, tipo de vuelo?\n",
    "¿Qué variables esperarías que más influyeran en predecir atrasos?\n",
    "4. Entrena uno o varios modelos (usando el/los algoritmo(s) que prefieras) para estimar la probabilidad de atraso de un vuelo.\n",
    "Siéntete libre de generar variables adicionales y/o complementar con variables externas.\n",
    "5. Evalúa tu modelo. ¿Qué performance tiene? ¿Qué métricas usaste para evaluar esa performance y por qué? ¿Por qué\n",
    "elegiste ese algoritmo en particular? ¿Qué variables son las que más influyen en la predicción? ¿Cómo podrías mejorar la\n",
    "performance?\n",
    "Aspectos a considerar\n",
    "Orden y claridad al momento de plantear un análisis, idea, código, etc.\n",
    "Creatividad para resolver el desafío.\n",
    "Código versionado en Git.\n",
    "No vamos a revisar excel, macros, códigos en R.\n",
    "No vamos a revisar desafíos que no lleguen en la fecha indicada\n",
    "Ante cualquier duda, deja explícitos tus supuestos\n",
    "No vivimos en tu cabeza, trata de expresarte lo mejor posible para explicar tus decisiones y respuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0069cb99",
   "metadata": {},
   "source": [
    "## Paso 1: Lectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024c5372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos librerías importantes para la tarea \n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe68f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leemos la base cruda con pandas\n",
    "raw = pd.read_csv('dataset_SCL.csv',\n",
    "                  dtype={'Fecha-I':'str',\n",
    "                         'Vlo-I':'str',\n",
    "                         'Ori-I':'str',\n",
    "                         'Des-I':'str',\n",
    "                         'Emp-I':'str',\n",
    "                         'Fecha-O':'str',\n",
    "                         'Vlo-O':'str'})  # da algunos problemas porque Vlo-I parecía ser numérico pero no lo es. Ej: \"405A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02deb765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw = pd.read_csv('dataset_SCL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fb5a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuestra lectura de datos es un dataframe?\n",
    "isinstance(raw, pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854dd926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sí lo es, pues lo leímos read_csv de pandas que la transforma en dataframe, luego:\n",
    "df = raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e37950c",
   "metadata": {},
   "source": [
    "## Paso 2: Exploración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7a5a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenemos 18 variables predictoras X1..X18 para nuestra variable respuesta Y (que, sospecho, debe ser la dif entre Fecha-I y Fecha-O)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2a20a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76426a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos a mirar unos primeros valores del df\n",
    "df.head(n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54cb33dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# algunas estadísticas descriptivas\n",
    "df.describe()\n",
    "# no nos dice nada pq lo único numérico hasta ahora son DIA MES AÑO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e37836",
   "metadata": {},
   "source": [
    "## Paso 3: Pre-procesamiento de Valores faltantes y extremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccb85a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos el módulo ML necesario\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebfb5de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1ae7c5",
   "metadata": {},
   "source": [
    "Tenemos suerte, sólo la columna Vlo-O tiene un espacio en blanco que presumiblemente sería un número: 200.\n",
    "\n",
    "Supuesto: Dado que Vlo-I es también 200. Podemos quitar la linea completa o bien extrapolarlo. Es razonable llenar el dato faltante.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea6438c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hay un dato faltante en la fila 6068 de la columna Vlo-O \n",
    "df.at[6068, 'Vlo-O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62adac30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo llenamos\n",
    "df.at[6068, 'Vlo-O'] = '200'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f565df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lo revisamos\n",
    "df.at[6068, 'Vlo-O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f862df50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luego ya no tenemos NANs\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0db5f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"date\"] = df[\"Fecha-O\"].astype(\"datetime64\")\n",
    "# df.groupby(df[\"date\"].dt.month).count().plot(kind=\"bar\")\n",
    "# muy confuso, hagámoslo más sencillo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e9ecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pequeño gráfico\n",
    "df.groupby(df[\"OPERA\"]).count().plot(kind=\"bar\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aad1c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# veamos la distribución de los vuelos\n",
    "# quiero contar los vuelos Vlo-O, a través 2017\n",
    "# luego, agrupados por Operador.\n",
    "\n",
    "freqByDate = df.groupby(['AÑO', 'MES']).size() \n",
    "print(freqByDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385297cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregados por Operador de vuelo y ordenados.\n",
    "freqByOp = df.groupby(['OPERA']).size()\n",
    "freqByOp.sort_values(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2032c8eb",
   "metadata": {},
   "source": [
    "Claramente Grupo Latam y Sky Airline tienen la mayor participación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69140f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos los valores extremos\n",
    "# No hay mucho outlier pues gran parte de la data es categórica (tranformaremos esto más adelante con Label_Encoding)\n",
    "# Y, si bien, la distribución de operadores está concentrada en pocos, no se consideran outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd62d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3fd6260",
   "metadata": {},
   "source": [
    "### Pregunta 1: ¿Cómo se distribuyen los datos? ¿Qué te llama la atención o cuál es tu conclusión sobre esto?\n",
    "\n",
    "En una 1era mirada tenemos: \n",
    "\n",
    "Una ventana temporal de un año (2017) de datos de vuelos de distintos operadores. Hay 2 datos de Enero 2018 que pueden confundirse en Enero de 2017 si hacemos agregación por MES solamente, pero para temas de distribución lo omitiremos.\n",
    "\n",
    "1. Fecha-I y Fecha-O tienen formato \"m/d/aaaa hh:mm\"\n",
    "2. I: Programado, lo planeado.\n",
    "3. O: Operación, lo que realmente ocurrio.\n",
    "\n",
    "Llama la atención que falta un dato en el registro posición 6068, que está en blanco. Pero bajo el supuesto de que, salvo 120 casos, Vlo-I = Vlo-O, lo llenamos con el número 200.\n",
    "\n",
    "Mirando sólo descriptivamente la distribución de la cantidad de vuelos (operación) por fecha (agregación Año Mes) tenemos:\n",
    "\n",
    "1. Se ve que la curva parte alta en Enero 2017 luego baja, supuestamente por temporada baja.\n",
    "2. Se ve un peak en Julio, supuestamente vuelos internacionales que persiguen el calorcito de fin de año en el hemisferio Sur.\n",
    "3. Hay otro peak en Septiembre, supuestamente por feriados alrededor del 18, porque parten a mitad de la 2da semana.\n",
    "4. Se ve que desde Octubre 2017 vuelve a subir la curva hasta el máximo en Diciembre 2017, Navidad y verano en hemisferio Sur.\n",
    "\n",
    "Me parece que habría que definir nuevas caracteristicas según lo solicitado, porque queremos modelar la diferencia entre las Fecha-I y Fecha-O, y en qué unidades medirlo. Definir también qué es un atraso. Además, según la distribución de vuelos en el año, podriamos decir algo sobre la temporada pues en verano (del hemisferio sur) hay una más vuelos que en invierno, hace sentido.\n",
    "\n",
    "En el paso 4 vamos a definir lo que necesitemos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6faa45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "661fc42d",
   "metadata": {},
   "source": [
    "## Paso 4: Definimos nuevas características"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8224ee",
   "metadata": {},
   "source": [
    "Definamos nuevas características (synthetic_features):\n",
    "\n",
    "1. temporada_alta: 1 si Fecha-I está entre 15-Dic y 3-Mar, o 15-Jul y 31-Jul, o 11-Sep y 30-Sep, 0 si no.\n",
    "2. dif_min: diferencia en minutos entre Fecha-O y Fecha-I .\n",
    "3. atraso_15: 1 si dif_min > 15, 0 si no.\n",
    "4. periodo_dia: mañana (entre 5:00 y 11:59), tarde (entre 12:00 y 18:59) y noche (entre 19:00 y 4:59), en base a Fecha-I.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c70554",
   "metadata": {},
   "source": [
    "### 4.1. Definimos temporada_alta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44716e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se realizó 4.4.periodo_dia antes que 4.1.temporada_alta, pero son similares.\n",
    "# Supuesto 1: Sin incluir extremos de las fechas.\n",
    "# Supuesto 2: la condición (Fecha-I está entre 15-Dic y 3-Mar) supone que es antes de 3-Mar y después de 15-Dic,\n",
    "# para que tenga sentido la condición. De otro modo, tendríamos que llamar temporada alta entre el 3-Mar a 15 Dic, lo cuál estaría erroneo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d231306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6757886",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cambiamos las fechas a objeto datatime\n",
    "from datetime import datetime\n",
    "\n",
    "df['Fecha-O'] = pd.to_datetime(df['Fecha-O'], errors='coerce')\n",
    "df['Fecha-I'] = pd.to_datetime(df['Fecha-I'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a053d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fecha-I es type object, lo pasaremos a datetime\n",
    "df['Fecha-I']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6948a3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo pasamos a datetime para poder compararlo más abajo en las condiciones\n",
    "#df['Fecha-I'] = pd.to_datetime(df['Fecha-I'], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3b51ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Fecha-I']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778a15c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import datetime\n",
    "# extraemos la parte dia mes de la fecha \n",
    "dateI = df['Fecha-I'].dt.date\n",
    "#time = df['Fecha-I'].dt.strftime('%H:%M')\n",
    "#dateI = pd.to_datetime(dateI, format='%Y-%m-%d %H:%M:%S')\n",
    "dateI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96f35bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vemos que funcione la comparación\n",
    "dateI > datetime.date(2017, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c33f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# usaremos np.select() igual que en 4.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88f561e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos la lista de condiciones\n",
    "conditions = [\n",
    "    (dateI < datetime.date(2017, 3,3)),       # está antes de 3-Mar\n",
    "    (dateI > datetime.date(2017, 12, 15)),    # está después de 15-Dic \n",
    "    (dateI > datetime.date(2017, 7, 15)) & (dateI < datetime.date(2017, 7, 31)), # está entre 15-Jul y 31-Jul\n",
    "    (dateI > datetime.date(2017, 9, 11)) & (dateI < datetime.date(2017, 9, 30))  # está entre 11-Sep y 30-Sep\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdc06f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos la lista de valores para cada una de esas condiciones\n",
    "values = ['1','1','1','1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661fcb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos la nueva columna y usamos np.select para asignar valores según nuestra lista como argumentos\n",
    "df['temporada_alta'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eeac69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['temporada_alta'] = df['temporada_alta']*1           # transformar falsos a 0\n",
    "df['temporada_alta'] = df['temporada_alta'].astype(int) # lo quiero int32 igual que atraso_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afed0b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# revisamos la columna para corroborar.\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    print(df[['Fecha-I', 'temporada_alta']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b0c321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# también revisar que haya quedado con tipo int32 \n",
    "df.info()\n",
    "# Pasemos al siguiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15451f52",
   "metadata": {},
   "source": [
    "### 4.2. Definimos dif_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde25210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# revisamos qué tipo de objeto son las fechas\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ec737c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cambiamos las fechas a objeto datatime\n",
    "from datetime import datetime\n",
    "\n",
    "df['Fecha-O'] = pd.to_datetime(df['Fecha-O'], errors='coerce')\n",
    "df['Fecha-I'] = pd.to_datetime(df['Fecha-I'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091b14f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# revisamos que hayan cambiado a objeto tipo datatime\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5328205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luego de cambiar el tipo, hacemos diferencia de tiempo, medido en minutos\n",
    "df['dif_min'] = (df['Fecha-O'] - df['Fecha-I']).dt.total_seconds() / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cefd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalmente, queda definida la diferencia:\n",
    "df['dif_min']\n",
    "# los números positivos indica la cantidad de minutos de atraso.\n",
    "# notar que un número negativo implica que el vuelo llegó antes de lo esperado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1117861c",
   "metadata": {},
   "source": [
    "### 4.3. Definimos atraso_15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dbf6026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vamos a definir un atraso cuando dif_min sean más de 15 min:\n",
    "\n",
    "df['atraso_15'] = df['dif_min'] > 15 # def condición\n",
    "df['atraso_15'] = df['atraso_15']*1  # convierte los falses en 0 y trues en 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5bd82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['atraso_15']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485d78f1",
   "metadata": {},
   "source": [
    "### 4.4. Definimos periodo_dia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d71460",
   "metadata": {},
   "source": [
    "definimos: periodo_dia: mañana (entre 5:00 y 11:59), tarde (entre 12:00 y 18:59) y noche (entre 19:00 y 4:59), en base a Fecha-I.\n",
    "\n",
    "quiero extraer hh:mm de cada fecha, y hacer condiciones.\n",
    "El pseudo sería algo así:\n",
    "\n",
    "si (Fecha-I > 05:00) AND (Fecha-I < 11:59) then periodo_dia == \"mañana\"\n",
    "\n",
    "si (Fecha-I > 12:00) AND (Fecha-I < 18:59) then periodo_dia == \"tarde\"\n",
    "\n",
    "si (Fecha-I > 19:00) OR (Fecha-I < 04:59) then periodo_dia == \"noche\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3209418d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if (df['Fecha-I'] > datetime.time(5, 00)) & (df['Fecha-I'] < datetime.time(11, 59)):\n",
    "#    df['periodo_dia'] == \"mañana\"\n",
    "    \n",
    "# el problema acá es que datetime.time no es del mismo tipo que Fecha-I.\n",
    "# pensemos... >>> 3 doritos después: podría ser con una lista de condiciones y usar np.select()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0fe6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "# extraemos la parte tiempo de la fecha \n",
    "time = df['Fecha-I'].dt.time\n",
    "#time = df['Fecha-I'].dt.strftime('%H:%M')\n",
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adde07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# comparamos según el pseudo anterior:\n",
    "time > datetime.time(19, 00)\n",
    "# estos sí se pueden comparar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea09cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos la lista de condiciones\n",
    "conditions = [\n",
    "    (time >= datetime.time(5, 00)) & (time <= datetime.time(11, 59)),\n",
    "    (time >= datetime.time(12, 00)) & (time <= datetime.time(18, 59)),\n",
    "    (time >= datetime.time(19, 00)),\n",
    "    (time <= datetime.time(4, 59))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089183bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos la lista de valores para cada una de esas condiciones\n",
    "values = ['mañana', 'tarde', 'noche', 'noche']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a435c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creamos la nueva columna y usamos np.select para asignar valores según nuestra lista como argumentos\n",
    "df['periodo_dia'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c929c159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# revisamos la columna para corroborar. Hay 27 periodo_dia == 0, veamos por qué.\n",
    "x = df.pivot_table(\n",
    "    index=['periodo_dia'], columns=\"atraso_15\", aggfunc=\"size\", fill_value=0\n",
    ").reset_index()\n",
    "x.columns.name = None\n",
    "print(x)\n",
    "\n",
    "# Aps, fue porque estaba todo con símbolos estrictos (<, >), se solucionó cuando colocamos = pues la comparación es al minuto.\n",
    "# Solucionado, ahora ya no aparecen los ceros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdeeb304",
   "metadata": {},
   "source": [
    "## Paso 5: Exportamos las columnas creadas al archivo \"synthetic_features.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd7e8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338878e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportamos las columnas a un csv en la misma carpeta, ordenados con el mismo índice que el dataset\n",
    "export_columns = ['dif_min','atraso_15','periodo_dia','temporada_alta']\n",
    "df.loc[:,export_columns].to_csv('synthetic_features.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6a7db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# si no se pueden nombrar\n",
    "# export_columns = [19:22]\n",
    "# df.iloc[:,export_columns].to_csv('new.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c5f8e3",
   "metadata": {},
   "source": [
    "## Paso 6: Preguntas\n",
    "1. ¿Cómo se compone la tasa de atraso por destino, aerolínea, mes del año, día de la semana, temporada, tipo de vuelo?\n",
    "2. ¿Qué variables esperarías que más influyeran en predecir atrasos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1026dbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# miremos el dataframe con los nuevos features\n",
    "df.head()\n",
    "# En mi opinión sería útil mirar esto con alguna herramienta de BI y visualización como PowerBI, se puede llegar a insights rápido y muchas veces sirven para elegir cómo modelar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebefa0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8ea655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preguntémonos por: destino, aerolínea, mes del año, día de la semana, temporada, tipo de vuelo\n",
    "# Preguntémonos por: SIGLADES, OPERA, MES, DIANOM, temporada_alta, TIPOVUELO\n",
    "# Hagamos las agregaciones para entender qué sucede:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a2c857",
   "metadata": {},
   "outputs": [],
   "source": [
    "By_SIGLADES = df.groupby(['atraso_15','SIGLADES']).size() \n",
    "# By_SIGLADES.sort_values(axis=0)\n",
    "print(By_SIGLADES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab9460a",
   "metadata": {},
   "outputs": [],
   "source": [
    "By_OPERA = df.groupby(['atraso_15','OPERA']).size()\n",
    "# By_OPERA.sort_values(axis=0)\n",
    "print(By_OPERA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826ddb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "By_DIANOM = df.groupby(['atraso_15','DIANOM']).size() \n",
    "# By_DIANOM.sort_values(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1478ae8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "By_MES = df.groupby(['atraso_15','MES']).size() # ordenado por mes\n",
    "By_MES\n",
    "# Hay una acumulación de atrasos en Jul, y Oct Nov y Dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3984776",
   "metadata": {},
   "outputs": [],
   "source": [
    "By_temporada_alta = df.groupby(['atraso_15','temporada_alta']).size() \n",
    "# By_temporada_alta.sort_values(axis=0)\n",
    "print(By_temporada_alta)\n",
    "# la mayor cantidad de atrasos ocurre en temporada baja, más del doble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025ec11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "By_TIPOVUELO = df.groupby(['atraso_15','TIPOVUELO']).size() \n",
    "# By_TIPOVUELO.sort_values(axis=0)\n",
    "print(By_TIPOVUELO)\n",
    "# Los atrasos ocurren más en vuelos internacionales (7048, un 56% del total de atrasos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6ee3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# otra forma para ver multivariable TIPOVUELO, temporada_alta\n",
    "# Aquí vemos distintas agregaciones de atraso_15, agrupado por temporada_alta agrupado y TIPOVUELO.\n",
    "\n",
    "x = df.pivot_table(\n",
    "    index=['temporada_alta', 'TIPOVUELO'], columns=\"atraso_15\", aggfunc=\"size\", fill_value=0\n",
    ").reset_index()\n",
    "x.columns.name = None\n",
    "print(x)\n",
    "\n",
    "# Por ejemplo, vemos que la mayor cantidad de atrasos (4635, un 38% del total) ocurre en temporada baja en vuelos internacionales.\n",
    "# También, que la menor cantidad de atrasos (1721, sólo 14% del total) ocurre en temporada alta en vuelos nacionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ca30ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# otra forma para ver los atrasos por temporada_alta y DIANOM.\n",
    "x = df.pivot_table(\n",
    "    index=['temporada_alta','DIANOM'], columns=\"atraso_15\", aggfunc=\"size\", fill_value=0\n",
    ").reset_index()\n",
    "x.columns.name = None\n",
    "print(x)\n",
    "\n",
    "# Vie, Lun y Jue hay más atrasos en temporada baja.\n",
    "# Vie, Jue, Mar y Mie hay más atrasos en temporada alta. Aunque no hay mucha dif entre estos últimos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330062f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# otra forma para ver los atrasos por TIPOVUELO, OPERA.\n",
    "x = df.pivot_table(\n",
    "    index=['TIPOVUELO','OPERA'], columns=\"atraso_15\", aggfunc=\"size\", fill_value=0\n",
    ").reset_index()\n",
    "x.columns.name = None\n",
    "print(x)\n",
    "\n",
    "# tiene sentido porque también hay más operadores internacionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba1766e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# otra forma para ver los atrasos por TIPOVUELO, periodo_dia.\n",
    "x = df.pivot_table(\n",
    "    index=['TIPOVUELO','periodo_dia'], columns=\"atraso_15\", aggfunc=\"size\", fill_value=0\n",
    ").reset_index()\n",
    "x.columns.name = None\n",
    "print(x)\n",
    "\n",
    "# tiene sentido porque también hay más operadores internacionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c978e71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2c5ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b73a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# probemos graficar df.\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cec3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La matriz de correlación sin Encoding luciría así:\n",
    "df_corrmatrix = df.corr()\n",
    "plt.figure(figsize=(20, 6))\n",
    "sns.heatmap(df_corrmatrix, vmax=1, annot=True, linewidths=.5)\n",
    "plt.xticks(rotation=30, horizontalalignment='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40985e83",
   "metadata": {},
   "source": [
    "Mirando la matrix del dataframe df sin Encoding, tenemos:\n",
    "1. Hay una relación entre atraso_15 y df_min, pero la diferencia en minutos fue usada para construir atraso_15 que es nuestra variable respuesta (Y), por tanto obviamente mostrará fuerza (artificial) en su relación, no es lo que buscamos.\n",
    "2. MES tiene algo de correlación (0.083) directa, pero no es suficiente.\n",
    "3. Hay una relación artificial entre temporada_alta y DIA, por motivos de construcción. Tal como en 1.\n",
    "4. Hay una relación artificial entre temporada_alta y MES, por motivos de construcción. Tal como en 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280f1266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "291b0361",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d49778fc",
   "metadata": {},
   "source": [
    "¿Cómo se compone la tasa de atraso por destino, aerolínea, mes del año, día de la semana, temporada, tipo de vuelo?\n",
    "¿Qué variables esperarías que más influyeran en predecir atrasos?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce899a22",
   "metadata": {},
   "source": [
    "La variable más influyente parece ser: MES\n",
    "\n",
    "DE las variables sintéticas, la más influyente parece ser: dif_min, pero esta la usamos para construir atraso_15, así que no sirve.\n",
    "\n",
    "Pero también parece razonable pensar que la hora de salida del vuelo tenga que ver con los retrasos.\n",
    "\n",
    "También parece razonable pensar que los vuelos anteriores retrazan a los sucesivos.\n",
    "\n",
    "Cabe la pregunta:\n",
    "¿Existe relación entre la hora de salida de un vuelo y su retrasos?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f760f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bueno para comparaciones.\n",
    "# breakfast_time = now.replace( hour=7, minute=30, second=0, microsecond=0 )\n",
    "# lunch_time = now.replace( hour=12, minute=30, second=0, microsecond=0 )\n",
    "# coffee_break = now.replace( hour=16, minute=00, second=0, microsecond=0 )\n",
    "\n",
    "# breakfast_time <= lunch_time <= coffee_break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb7dbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Útil\n",
    "# df['Fecha-I'] = pd.to_datetime(df['Fecha-I'], format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f0924a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Útil\n",
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "\n",
    "# df\n",
    "# df['Date'] = pd.date_range(start='01/01/2017', end='31/12/2017')\n",
    "# df['Value'] = np.random.randint(low=5, high=100, size=len(df))\n",
    "# df.set_index('Date', inplace=True)\n",
    "\n",
    "# df.plot()\n",
    "# plt.show()\n",
    "\n",
    "# df.plot(kind='bar')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de382b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b15e8bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da8db8de",
   "metadata": {},
   "source": [
    "## Paso 7: Label Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ed0df2",
   "metadata": {},
   "source": [
    "Transformaremos las siguientes características a tipo numérico mediante Label_Encoding:\n",
    "\n",
    "EMP-I, ORI-O, DES-O, EMP-O, DIANOM, TIPOVUELO, OPERA, SIGLAORI, SIGLADES, periodo_dia\n",
    "\n",
    "Sabemos que EMP-O = OPERA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ae442b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para ello habrá que hacer un Label_Encoding. Quiero transformar en número algunas variables: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947c0581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# le = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d06ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['label'] = le.fit_transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35002414",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b95f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b0705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debería droppear Fecha-I y Fecha-O para analizar sólo los numéricos.\n",
    "# df.drop(labels=['Fecha-I', 'Fecha-O'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ee236f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242942f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In order to convert data-frame column containing text to encoded values,\n",
    "# just use the function text_to_numbers it returns a dictonary of LabelEncoding.\n",
    "# Key is the column name that column LabelEncoder() as a value.\n",
    "# https://stackoverflow.com/questions/24458645/label-encoding-across-multiple-columns-in-scikit-learn\n",
    "# S.Rucinski\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def text_to_numbers(df):\n",
    "        le_dict = dict()\n",
    "        for i in df.columns:\n",
    "            if df[i].dtype not in [\"bool\", \"float32\", \"float64\", \"int32\", \"int64\", \"datetime64[ns]\"]: # no convierte las features de estos type\n",
    "                le_dict[i] = preprocessing.LabelEncoder()\n",
    "                df[i] = le_dict[i].fit_transform(df[i])\n",
    "    \n",
    "        return df, le_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd41a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y esta es f^(-1) de la f anterior. Es decir, es la función que nos permitirá recuperar el dataframe original.\n",
    "def numbers_to_text(df, le_dict):\n",
    "        for i in le_dict.keys():\n",
    "            df[i] = le_dict[i].inverse_transform(df[i])\n",
    "    \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1592ad52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usamos la función para el Encoding.\n",
    "# Notar que en la función text_to_numbers() no convertimos explícitamente algunas características, \n",
    "dfle2 = text_to_numbers(df)\n",
    "print(dfle2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf63e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(dfle2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4583a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como df_le es una 2-tupla pq tiene el diccionario en su 2do elemento, extraemos el 1er elemento que es el df ya transformado,\n",
    "# y lo dejamos como nuestro dataframe de insumo, lo llamamos dfle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a594bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "le_df = dfle2[0]\n",
    "le_dict = dfle2[1]\n",
    "le_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e556e2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5e2869",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Vemos como queda los tipos del dataframe. Todos int32 e int64, las fechas intactas\n",
    "# y el flotante que es dif_min también intacto.\n",
    "le_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d74bff1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Se ve mucho más como comida de algoritmos\n",
    "le_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab892561",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(le_df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecbd1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(le_dict)\n",
    "type(le_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd3dc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para devolvernos sólo tenemos que usar la función y darle 2 argumentos:\n",
    "# El dataframe convertido (dfle) y el diccionario del LE (le_dict).\n",
    "# Pero por ahora lo dejaremos comentado.\n",
    "\n",
    "# numbers_to_text(le_df, le_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f70ab7",
   "metadata": {},
   "source": [
    "## Paso 8: Gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c254c3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veamos unos pocos gráficos\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7edcfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6589a8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excluimos algunas columnas\n",
    "#df2 = df.loc[:, ~df.columns.isin(['ORI-I', 'ORI-O', 'SIGLAORI'])]\n",
    "#df2 = df.drop(['ORI-I', 'ORI-O', 'SIGLAORI'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7049c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# La matriz de correlación CON Encoding luciría así:\n",
    "\n",
    "df_corrmatrix = df.corr()\n",
    "plt.figure(figsize=(20, 6))\n",
    "sns.heatmap(df_corrmatrix, vmax=1, annot=True, linewidths=.5)\n",
    "plt.xticks(rotation=30, horizontalalignment='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7bda5c",
   "metadata": {},
   "source": [
    "Ignoremos por el momento SIGLAORI, ORI-I, ORI-O que se nos pasó en el Encoder y lo dejó en 0.\n",
    "También ignoremos, como vimos antes, dif_min porque lo usamos para construir atraso_15.\n",
    "Miremos la correlación entre atraso_15 (la que nos importa) y TIPOVUELO, hay una correlación inversa (-0.096), pero tiene poca fuerza.\n",
    "Miremos la correlación entre atraso_15 (la que nos importa) y MES, hay una correlación directa (0.083), pero tiene poca fuerza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0749464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definimos un boxplot para mirar graficamente.\n",
    "#bp1 = le_df[['atraso_15','periodo_dia']]\n",
    "#sns.boxplot(x=\"variable\", y=\"value\", data=pd.melt(bp1)) # melt despivotea\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4a59bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a783a3f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eac6144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8845a446",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1400869f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a8422a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8e4cb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8c5e84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8412a803",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152e7da3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c15e617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a6cbcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fd4fd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f0be1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc56f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd3fd00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e833430f",
   "metadata": {},
   "source": [
    "## Paso 9: Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7acef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# posibles modelos a priori dado que la Y (atraso_15) es binaria: Logistic, RandomForest, XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125e33b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbaf713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5b192c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278ee369",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
